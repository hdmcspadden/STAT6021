progress2 = progress1 / criticalvalue2d
progress2
progress3 = progress2^2
progress3
progress4  = progress3 / MSE
progress4
UNKNOWNPART = progress4 - OneOvern
UNKNOWNPART
progress1 = 82.7022 - 81.7576
progress2 = progress1 / criticalvalue2d
#progress2
progress3 = progress2^2
#progress3
progress4  = progress3 / MSE
#progress4
UNKNOWNPART = progress4 - OneOvern
print(paste("Our UNKNOWNPART is: ",UNKNOWNPART))
lower.prediction  = 81.7576 - ((criticalvalue2d) * sqrt((MSE) * (1 + OneOvern + UNKNOWNPART)))
lower.prediction  = 81.7576 - ((criticalvalue2d) * sqrt((MSE) * (1 + OneOvern + UNKNOWNPART)))
upper.prediction = 81.7576 + ((criticalvalue2d) * sqrt((MSE) * (1 + OneOvern + UNKNOWNPART)))
print(paste("Our 95% CI prediction interval for x of 4.5 is: ", lower.prediction, " - ", upper.prediction))
A = matrix(
+   c(2, 4, 3, 1, 5, 7), # the data elements
+   nrow=2,              # number of rows
A <- matrix(
+   c(2, 4, 3, 1, 5, 7), # the data elements
+   nrow=2,              # number of rows
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A^-1
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.inv = A^-1
A * A
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.inv = A^-1
A.transA = A * A.inv
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.inv = A^-1
A.transA = A * A.inv
A.transA
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.inv = A^-1
A.inv
A.transA = A * A.inv
A.transA
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.trans = t(A)
A.trans
A.A.trans.inv = (A * A.trans)^-1
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.trans = t(A)
A.trans
A.A.trans.inv = (A %*% A.trans)^-1
A.A.trans.inv
A <- matrix(c(2, 4, 3, 1, 5, 7), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.trans = t(A) # t() is matrix transpose
A.trans
A.A.trans.inv = (A %*% A.trans)^-1 # %*% is matrix multiplication
A.A.trans.inv
Fcompare = qf(.975, df1=5, df2=2)
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = qf(.975, df1 = 2, df2 = 22)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = qf(.975, df1 = 2, df2 = 22)
FcompareExample
pf(261.24,2,22)
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = qf(.975, df1 = 2, df2 = 2100)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = qf(.975, df1 = 5, df2 = 2)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = pf(.975, df1 = 5, df2 = 2)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.975, df1=5, df2=2)
Fcompare
FcompareExample = pf(.975, df1 = 5, df2 = 2)
FcompareExample
?pf
pt(.975,22)
qt(.975,22)
qt(.975,22) #critical value of two tailed 95% CI for n-p == 22 (25 data points, 2 regressors)
A <- matrix(c(2, 4, 3, 1, 5, 7,4,5,6,8,5,3), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.trans = t(A) # t() is matrix transpose
A.trans
A.A.trans.inv = (A %*% A.trans)^-1 # %*% is matrix multiplication
A.A.trans.inv
setwd("~/UVaCode/R/STAT6021/Module04")
data <- read.table("delivery.txt", header=TRUE ,sep="")
data <- read.table("delivery.txt", header=TRUE ,sep="")
attach(data)
head(data,10)
summary(data)
describe(data)
library(Hmisc)
install.packages("Hmisc")
describe(data)
summary(data)
result<-lm(Delivery~Number+Distance)
summary(result)
qf(0.05, 2, 22)
confint(result,level = 0.95)
predict.lm(result, newdata, level=0.95, interval="confidence")
newdata<-data.frame(Number=20, Distance=200) # create the new data point to run CIs of mean and predicted value
predict.lm(result, newdata, level=0.95, interval="confidence")
predict.lm(result, newdata, level=0.95, interval="prediction")
qf(0.05, 2, 22) # including this because in some later sections we do not get p value of F to compare, notice .95 for 95% test
qf(0.95, 2, 22) # including this because in some later sections we do not get p value of F to compare, notice .95 for 95% test
qr(0.05,2,22)
qr(0.05,2,22)
qf(0.05,2,22)
qf(0.95, 2, 22) # including this because in some later sections we do not get p value of F to compare, notice .95 for 95% test
confint(result,level = 0.95) # 95% confidence interval of the regression coefficients
newdata<-data.frame(Number=20, Distance=200) # create the new data point to run CIs of mean and predicted value
predict.lm(result, newdata, level=0.95, interval="confidence")
predict.lm(result, newdata, level=0.95, interval="prediction")
# a residual plot?
plot(result$fitted.values,result$residuals, main="MLR: Residuals vs. Fitted Values")
abline(h=0,col="red")
# ACF plot?
acf(result$residuals, main="MLR: ACF of Residuals")
# Normal probability or QQ plot of residuals
qqnorm(result$residuals)
qqline(result$residuals, col="red")
# Box BOx ??
library(MASS)
boxcox(result, lambda = seq(0.6, 1.6, 0.01))
boxcox(result, lambda = seq(-1, 1, 0.01))
boxcox(result, lambda = seq(0, 1, 0.01))
setwd("~/UVaCode/R/STAT6021/Module04")
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
shape(nflData)
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
pairs(nflData)
pairs(nflData,lower.panel = NULL)
#pairs(nflData)
pairs(nflData,lower.panel = NULL)
# set my chuck width
opts_chunk$set(out.width='900px', dpi=200)
#pairs(nflData)
pairs(nflData,lower.panel = NULL)
#pairs(nflData)
pairs(nflData,lower.panel = NULL)
#pairs(nflData)
pairs(nflData,lower.panel = NULL)
cor(nflData)
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so it doesn't get caught in threshold
ok <- apply(abs(corWorking) >= threshold, 1, any)
nflData.cor[ok, ok]
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so it doesn't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold
corWorking <- nflData.cor
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so it doesn't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.6 # set a correlation threshold
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflModel.x2x7x8 <-lm(y ~ x2 + x7 + x8)
nflModel.x2x7x8
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
estimated.wins <- -1.808 + (.0036 * 2000) + (.194 * 48) - (.0048 * 2350)
estimated.wins
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.95, df1=5, df2=2)
Fcompare
FcompareExample = qf(.955, df1 = 5, df2 = 2)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.95, df1=5, df2=2)
Fcompare
FcompareExample = qf(.95, df1 = 5, df2 = 2)
FcompareExample
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.95, df1=5, df2=2)
Fcompare
*FcompareExample = qf(.95, df1 = 5, df2 = 2)
# run an example with a two-sided alpha 5% k = 5 and n = 8
Fcompare = qf(.95, df1=5, df2=2)
Fcompare
#FcompareExample = qf(.95, df1 = 5, df2 = 2)
#FcompareExample
summary(nflModel.x2x7x8)
anova(nflModel.x2x7x8)
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
dim(dataset)
# load the data
nflData <- read.table("nfl.txt", header=TRUE ,sep="")
attach(nflData)
head(nflData)
dim(nflData)
summary(nflModel.x2x7x8)
anova(nflModel.x2x7x8)
criticalValue = qf(0.95, df1=3, df2 = 24)
print(paste('criticalValue: ', criticalValue))
x7.criticalValue = qt(.95, 22)
x7.criticalValue
x7.criticalValue = qt(.975, 22)
x7.criticalValue
x7.criticalValue = qt(.975, 22)
print(paste("x7 critical value: ", x7.criticalValue))
par(mfrow=c(2,2)) # 2 rows, 2 columns - there will be three panes to look through
# Residual plot
plot(nflModel.x2x7x8$fitted.values,nflModel.x2x7x8$residuals, main="MLR: Residuals vs. Fitted Values")
abline(h=0,col="red")
# ACF Plot
acf(nflModel.x2x7x8$residuals, main="MLR: ACF of Residuals")
# QQ Plot of Residuals
qqnorm(nflModel.x2x7x8$residuals)
qqline(nflModel.x2x7x8$residuals, col="red")
# Why not add the Box Cox too
library(MASS)
boxcox(nflModel.x2x7x8, lambda = seq(0, 1, 0.01))
View(nflData)
View(nflData)
par(mfrow=c(2,2)) # 2 rows, 2 columns - there will be three panes to look through
# Residual plot
plot(nflModel.x2x7x8$fitted.values,nflModel.x2x7x8$residuals, main="MLR: Residuals vs. Fitted Values")
abline(h=0,col="red")
# ACF Plot
acf(nflModel.x2x7x8$residuals, main="MLR: ACF of Residuals")
# QQ Plot of Residuals
qqnorm(nflModel.x2x7x8$residuals)
qqline(nflModel.x2x7x8$residuals, col="red")
# Can't run BoxCox because there is a 0 value
#library(MASS)
#boxcox(nflModel.x2x7x8, lambda = seq(0, 1, 0.01))
# create the new model
nflModel.x1x2x7x8 <-lm(y ~ x1 + x2 + x7 + x8)
nflModel.x1x2x7x8
# create the new model
nflModel.x1x2x7x8 <-lm(y ~ x1 + x2 + x7 + x8)
nflModel.x1x2x7x8
summary(nflModel.x1x2x7x8)
# create the new model
nflModel.x1x2 <-lm(y ~ x1 + x2)
nflModel.x1x2
summary(nflModel.x1x2)
nflData.cor = cor(nflData)
threshold <- 0.8 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.6 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.8 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.7 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.55 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
nflData.cor = cor(nflData)
threshold <- 0.6 # set a correlation threshold, is there a standard? Not really
corWorking <- nflData.cor
diag(corWorking) <- 0 # set diagonal to 0 so 1's of unrelated don't get caught in threshold
nflData.cor.related <- apply(abs(corWorking) >= threshold, 1, any) # apply the filter to the absolute value of the correlations between variables.
nflData.cor[nflData.cor.related, nflData.cor.related]
# load the data
?swiss
head(swiss)
head(swiss)
summary(swiss)
head(swiss)
summary(swiss)
head(swiss)
summary(swiss)
head(swiss)
summary(swiss)
head(swiss)
summary(swiss)
pairs(swiss,lower.panel = NULL)
pairs(swiss,lower.panel = NULL)
pairs(swiss,lower.panel = NULL)
pairs(swiss,lower.panel = NULL)
# load the data
?swiss
attach(swiss)
head(swiss)
summary(swiss)
pairs(swiss,lower.panel = NULL)
swissModel <-lm(Fertility ~ Agriculture + Examination + Education + Catholic)
swissModel
summary(swiss)
summary(swissModel)
swissModel <-lm(Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality)
swissModel
summary(swissModel)
pt(-abs(3.891),110)
pt(-abs(3.891),108)
pt(-abs(3.891),5)
B2.teststatistic = -0.014071 / 0.022708
print(paste("The B2 test statistic is: ", B2.teststatistic))
B2.teststatistic = -0.014071 / 0.022708
print(paste("The B2 test statistic is: ", B2.teststatistic))
B3.teststatistic = 0.020383 / 0.005524
print(paste("The B3 test statistic is: ", B3.teststatistic))
B2.teststatistic = -0.014071 / 0.022708
print(paste("The B2 test statistic is: ", B2.teststatistic))
B2.teststatistic = -0.014071 / 0.022708
print(paste("The B2 test statistic is: ", B2.teststatistic))
B2.pvalue = 2*pt(-abs(B2.teststatistic), df=(113 - 4 - 1))  # calc p Value
print(paste("The B2 p-value is: ", B2.pvalue))
# calculate the B2 test statistics
B2.teststatistic = -0.014071 / 0.022708
print(paste("The B2 test statistic is: ", B2.teststatistic))
# calculate the B2 p-value of the test statistic
B2.pvalue = 2*pt(-abs(B2.teststatistic), df=(113 - 4 - 1))  # calc p Value
print(paste("The B2 p-value is: ", B2.pvalue))
# calculate the B2 critical value to compare the test statistic to
criticalValue = qt(0.975, (113 - 4 - 1))
print(paste("The critical value is: ", criticalValue))
?confint
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- qt((0.975 / 3), (113 - 4 - 1))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 - (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI-.high))
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- qt((0.975 / 3), (113 - 4 - 1))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 - (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI.high))
B2.CI.low <- B2 - (delta * se.B2)
B2.CI.high <- B2 - (delta * se.B2)
print(paste("The simultaneous 95% CI for B2 is: ", B2.CI.low, " - ", B2.CI.high))
B3.CI.low <- B3 - (delta * se.B3)
B3.CI.high <- B3 - (delta * se.B3)
print(paste("The simultaneous 95% CI for B3 is: ", B3.CI.low, " - ", B3.CI.high))
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- qt((0.975 / 3), (113 - 4 - 1))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 + (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI.high))
B2.CI.low <- B2 - (delta * se.B2)
B2.CI.high <- B2 + (delta * se.B2)
print(paste("The simultaneous 95% CI for B2 is: ", B2.CI.low, " - ", B2.CI.high))
B3.CI.low <- B3 - (delta * se.B3)
B3.CI.high <- B3 + (delta * se.B3)
print(paste("The simultaneous 95% CI for B3 is: ", B3.CI.low, " - ", B3.CI.high))
View(nflData)
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- abs(qt((0.975 / 3), (113 - 4 - 1)))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 + (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI.high))
B2.CI.low <- B2 - (delta * se.B2)
B2.CI.high <- B2 + (delta * se.B2)
print(paste("The simultaneous 95% CI for B2 is: ", B2.CI.low, " - ", B2.CI.high))
B3.CI.low <- B3 - (delta * se.B3)
B3.CI.high <- B3 + (delta * se.B3)
print(paste("The simultaneous 95% CI for B3 is: ", B3.CI.low, " - ", B3.CI.high))
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- abs(qt((1 - (.05/6)), (113 - 4 - 1)))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 + (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI.high))
B2.CI.low <- B2 - (delta * se.B2)
B2.CI.high <- B2 + (delta * se.B2)
print(paste("The simultaneous 95% CI for B2 is: ", B2.CI.low, " - ", B2.CI.high))
B3.CI.low <- B3 - (delta * se.B3)
B3.CI.high <- B3 + (delta * se.B3)
print(paste("The simultaneous 95% CI for B3 is: ", B3.CI.low, " - ", B3.CI.high))
B1 <- 0.237209
se.B1 <- 0.060957
B2 <- -0.014071
se.B2 <- 0.022708
B3 <- 0.020383
se.B3 <- 0.005524
delta <- qt((1 - (.05/6)), (113 - 4 - 1))
B1.CI.low <- B1 - (delta * se.B1)
B1.CI.high <- B1 + (delta * se.B1)
print(paste("The simultaneous 95% CI for B1 is: ", B1.CI.low, " - ", B1.CI.high))
B2.CI.low <- B2 - (delta * se.B2)
B2.CI.high <- B2 + (delta * se.B2)
print(paste("The simultaneous 95% CI for B2 is: ", B2.CI.low, " - ", B2.CI.high))
B3.CI.low <- B3 - (delta * se.B3)
B3.CI.high <- B3 + (delta * se.B3)
print(paste("The simultaneous 95% CI for B3 is: ", B3.CI.low, " - ", B3.CI.high))
R2 <- 9139.4336 / 9256.2464
print(paste("R2 for the model is: ", R2))
R2.adj <- (116.8128 / (113-5)) / (9256.2464 / 113-1))
R2.adj <- (116.8128 / (113-5)) / (9256.2464 / (113-1))
print(paste("R2 Adjusted for the model is: ", R2.adj))
R2.adj <- 1.0816 / (9256.2464 / (113-1))
print(paste("R2 Adjusted for the model is: ", R2.adj))
A <- matrix(c(2, 4, 3, 1, 5, 7,4,5,6,8,5,3), nrow=2, ncol=3, byrow = TRUE)        # fill matrix by rows
A
A.trans = t(A) # t() is matrix transpose
A.trans
A.A.trans.inv = (A %*% A.trans)^-1 # %*% is matrix multiplication
A.A.trans.inv
A.A.trans = (A %*% A.trans)
A.A.trans
R2.adj <- 1 - (1.0816 / (9256.2464 / (113-1)))
print(paste("R2 Adjusted for the model is: ", R2.adj))
estimated.wins <- -1.808 + (.0036 * 2000) + (.194 * 48) - (.0048 * 2350)
estimated.wins
### need to add prediction
newdata <-data.frame(x2=2000,x7=48,x8=2350)
predict.lm(nflModel.x2x7x8,newdata,interval="prediction")
