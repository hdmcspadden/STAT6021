---
title: "Module06Sandbox"
author: "Diana McSpadden"
date: "10/1/2020"
output: html_document
---

# Module 06: Categorical Variables

Categorial, aka Qualitative Variables

observations into groups

What are the differences in the MLR model when predictors are categorical.

## ESSENTIAL QUESTIONS
1. How do we use indicator variables for categorical predictors in an MLR model?
1. What does it mean when there is an interaction between the predictors?
1. How do we interpret the MLR model when we have categorical predictors, with and without interaction?

one class has 0 for all indicator variables == **reference class**

**The coefficients for each indicator variable compare the mean response for that class with the reference class.**




## 6.2 Indicator Variables

Read Sections 8.1 to 8.2 of your textbook.

### 1. Describe how you would use indicator variables for this regression. 

**Answer**
Indicator variables are quantitative variables whose quant value is assigned based on a qualitative value of the corresponding categorical variable(s).

read pages 261 and 262 for desctriptions of indicator variables

In general, a qualitative variable with a levels is represented by (a-1) regressor variables (binary switches with values 0 or 1)


### 2. What is the interpretation of the regression coefficients β0, β1, β2 when there are no interactions? How does the interpretation change when there is interaction between the predictors? 

**Answer No Interactions**

When slopes are the same:

B0: When category is category 0, and quantitative variable is 0.

B1: In the book example, B1 is the change in response variable when the quantitative variable changes by 1 unit

B2: In the book example, B2 is the change in response variable when indicator variable changes from category 0 to category 1. and 95% confidence interval of B2 is described as "95% confidence that changing from category 0 to category 1 increases mean tool life between B2 low to B2 high."

**I like this description**
The coeffcient B2 for the indicator variable is the difference in the intercepts. Contextually, B2 is the difference in the average response between stock firms and mutual fund firms, when comparing firms of similar size.

In general, B2 shows how much higher (or lower) the mean response is for the class coded 1 than for the class coded 0, for any given level (or value) of x1.


**When slopes are different:**

For category 0:
B0: this is the intercept

B1: slope of category 0 

For categoyry 1:

Intercept is B0 + B2

Slope is B1 + B3

Where B3 is coefficient of x1x2

**Answer Interactions**


Add multiplier terms

E.g.
where :

x1 = square footage of home

x2, x3, x4 == 0 == no air conditioning

x2 = 1, x3,x4 = 0 == window units

x3 = 1, x2,x4 = 0 == heat pump

x4 = 1, x2,x3 = 0 == central air

Equation looks like:

**Y-hat = B0 + B1x1 + B2x2 + B3x3 + B4x4 + B5x1x2 + B6x1x3 + B7x1x4 + E**

**Interpreations of Coefficients**
B0: intercept for no air conditioning

B1: slope of no air conditioning

B0 + B2 = intercept window units

B1 + B5 = slope window units

B0 + B3 = intercept heat pump

B1 + B6 = slope window units

B0 + B4 = intercept central air

B1 + B7 = slope central air


### 3. Describe, in your own words, what interaction between the predictors means. 

**Answer**
Interaction between predictors, with categorical variables, means that the slope for the regression line for different categories is different. We expect the prediction to change by different amount per that same unit change depending on the category.

### 4. What assumption are we making regarding the model variance, σ2, when using indicator variables? 

sigma^2 will be artifically less than the actual value because it is calculated as SSE / (n - p)

and we are adding additional parameters the denominator will increase. Also, does the assumption that additional regressors always decreases SSE still apply to indicator variables?

**From Dr. Woo**: When using indicator variables, we are assuming the the error variance σ2 is the same across all classes of the categorical variable.

## 6.3 Regression and ANOVA

Read Section 8.3 of your textbook.

### Explain, in your own words, why the ANOVA problem can be treated as a regression problem ...
in which all of the regressors are indicator variables. 

each "treatment" in ANOVA can be thought of as a level of a categorical/qualitative factor.


With k treatments

B0 =  mew-k

Bi = mew-i = mew-k where i = 1,2,...,k-1

if H0 is true then B0 = mew and B1, B2 == 0.

which is basically they same as in linear regression model where H0 is that B0 (the intercept) is at least as good a prediction as when the other B's are used, and equals y-bar.

AND, we compare F0 against F alpha, k-1, k(n-1) which works out to F alpha, parameters - 1, kk - k which ends up equaling same as regression F critical value.


###How are the null and alternative hypotheses written ...
when we are testing if the population mean response variable is the same across all groups?

H0: tau1 = tau2 = ... = tauk == 0 where tau is the effect of each treatment. That all populations are equal. There is no effect of treatment

Ha: tau-i != 0 for at least 1 i.


## 6.3: Recap of Module 6

one class has 0 for all indicator variables == **reference class**

**The coefficients for each indicator variable compare the mean response for that class with the reference class.**

### Example WITHOUT INTERACTIONS

response variable == income of Americans

x1 = years in school

three political affiliations: Democrat, Republican, Independent

Let's make Independent the **reference class**

I1 = 1 if Democrat, 0 otherwise

I2 = 1 if Republican, 0 otherwise

E(Y|x) = B0 + B1x1 + B2I1 + B3I2


For Democrats E(Y|x) = B0 + B1x1 + B2 == B0 + B2 + B1x1 (1)

For Republicans E(Y|x) = B0 + B3 + B1x1 (2)

For Independents Y*Y|x) = B0 + B1x1 (3)


The coefficient B2 shows difference between democrats and reference class (Independents) assuming x1 is constant. B2 is the difference in mean for democrats vs independents with the same years of education.

How do we compare democrats with republications (1) - (2) == B2 - B3 gives difference between democrats and republicans when years of education is held constant.


### EXAMPLE WITH INTERACTIONS

Additive effects assume that each predictor's effect on the response **does not depend** on the value(s) of the other predictors.

**Interaction effects** allow the effect of one predictor on the response to depend on the value of the other predictor(s).

says we are no longer keeping them constant.

y = sales prices of homes

x1 = square footage

x2 = whether the home has air conditioning I1 == 1 home has air conditioning, I1 == 0 home does not have air conditioning.

E(Y|x) = B0 + B1x1 + B2I1 + B3x1I1

For No air conditioning E(Y|x) = B0 + B1x1

For air conditioning E(Y|x) = B0 + B1x1 + B2 + B3x1 == B0 + B2 + (B1 + B3)x1 i.e. the slope and intercept is different.

**IF Interaction terms/coefficients** are significant (the x1I1 in example) you must always leave in the lower order terms, EVEN if the t-tests indicate they are not significant.


** You MUST make sure R see categorical variables as categorical and NOT quantitative** Use factor() function.

Use factor() function to check.

If data set uses dummy codes you don't have to do anything. The lm() converts categorical variables into dummy codes "behind the scenes"

**Check your reference class** use relevel() function if needed.




