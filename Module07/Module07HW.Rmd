---
title: "Module 07 Homework"
author: "Diana McSpadden"
date: "10/10/2020"
output: html_document
---
# Stat 6021: Homework Set 7

## Name: H. Diana McSpadden
### UID: hdm5s
### 10.15.2020

#### Attended Study Group With

You will continue to use the birthwt data set from the MASS package for this question.

The data were collected at Baystate Medical Center, Springfield, Mass during 1986.

The data contain information regarding weights of newborn babies as well as a number of potential predictors. Before proceeding, be sure to read the documentation about the data set by typing ?birthwt. The goal of the data set is to relate the birthweight of newborns with the characteristics of their mothers during pregnancy.

```{r q0-1}
# attach the data
library(MASS)

attach(birthwt)
head(birthwt,5)

?birthwt

```

The birthwt data frame has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986.

low: indicator of birth weight less than 2.5 kg.

age: mother's age in years.

lwt: mother's weight in pounds at last menstrual period.

race: mother's race (1 = white, 2 = black, 3 = other).

smoke: smoking status during pregnancy.

ptl: number of previous premature labours.

ht: history of hypertension.

ui: presence of uterine irritability.

ftv: number of physician visits during the first trimester.

bwt: birth weight in grams.

## Question 1a) Which of these variables are categorical? 
Ensure that R is viewing the categorical variables correctly (i.e. use the is.numeric() function to check). If needed, use the factor() function to force R to treat the necessary variables as categorical.

```{r q1a-1}

low<-factor(low)
race<-factor(race)
smoke<-factor(smoke)
ht<-factor(ht)
ui<-factor(ui)

is.factor(low) 

is.factor(race)

is.factor(smoke)

is.factor(ht)

is.factor(ui)

```

**Answer 1a**

The following predictor variables are categorical:
* low: indicator of birth weight less than 2.5 kg.
* race: mother's race (1 = white, 2 = black, 3 = other).
* smoke: smoking status during pregnancy.
* ht: history of hypertension.
* ui: presence of uterine irritability.


## Question 1b) A classmate of yours makes the following suggestion: 
We should remove the variable low as a predictor for the birth weight of babies." 

Do you agree with your classmate? Briefly explain. Hint: you do not need to do any statistical analysis to answer this question.

**Answer 1b**
Yes, I agree with the classmate. Low is a yes/no (1/0) indicator of whether the baby is low birthweight. It will be perfectly correlated with bwt.


## Question 1c) Based on your answer to part 1b, perform all possible regressions ...
using the regsubsets() function from the leaps package. 

Write down the predictors that lead to a first-order model having the best:

1. adjusted R2,
2. mean-sqaured error,
3. Mallow's Cp,
4. BIC.

**Working on Question 1c**

**First**, drop the low regressor

```{r q1c-1}
# Drop the low column by using subset
birthwtData <- subset(birthwt, select = -c(low)) # remove the low column

head(birthwtData)
```

**Second**, use the regsubsets() function
```{r q1c-2}
# add the leaps library
library(leaps)

# create all the regsubsets
# set nbest to 8 because there are 8 predictor variables
allreg <- regsubsets(bwt ~., data=birthwtData, nbest=8)

```

For R2Adj, MSE, Mallows and BIC get the "best" models.

```{r q1c-3}
##create a "data frame" that stores the predictors in the various models considered as well as their various criteria
best <- as.data.frame(summary(allreg)$outmat)

best$adjr2 <- summary(allreg)$adjr2
best$p <- as.numeric(substr(rownames(best),1,1))+1
best$mse <- (summary(allreg)$rss)/(dim(data)[1]-best$p)

best$cp <- summary(allreg)$cp

best$bic <- summary(allreg)$bic

##sort by various criteria
best[order(best$adjr2),] # want largest
best[order(best$mse),] # want smallest
best[order(best$cp),] # want smallest
best[order(best$bic),] # want smallest
```
**Answer 1c**

**Best R2Adj** model uses the following predictors: lwt, race, smoke, ht, ui.

**Best MSE** model uses the following predictors: race, smoke, ui.

**Best Cp** model uses the following predictors: lwt, race, smoke, ht, ui.

**Best BIC** model uses the following predictors: race, smoke, ht, ui.

## Question d) Based on your answer to part 1b, use backward selection to find the best model according to AIC. 

Start with the first-order model with all the predictors. What is the regression equation selected?

```{r q1d-1}
# only the intercept
regnull <- lm(bwt~1, data=birthwtData) # intercept only/empty model == ENDING POINT for backward

# model with all predictors (except low)
regfull <- lm(bwt~., data=birthwtData) # full model == END POINT

step(regfull, scope=list(lower=regnull, upper=regfull), direction="backward")

```

**Answer 1d**

**formula** = bwt ~ lwt + race + smoke + ht + ui

## Question 2) (No R required) The data for this question are 36 monthly observations ...
on variables affecting sales of a product. 

The objective is to determine an efficient model for predicting and explaining market share sales, Share, which is the average monthly market share for the product, in percent. 

The predictors are average monthly price in dollars, price, amount of advertising exposure based on gross Nielson rating, nielsen, whether a discount price was in effect, discount (1 if discount, 0 otherwise), whether a package promotion was in effect, promo (1 if promotion, 0 otherwise), and time in months, time.

**Working on Question 1**

Knowns:
1. y/response variable = Share
2. Regressor/predictor variables:
  1. price - avg monthly price in dollars
  2. nielsen - amount of advertising exposure based on gross Nielson rating
  3. discount: categorical 1 if discount, 0 otherwise
  4. promo: categorical, 1 if under promo, 0 otherwise
  5. time: time in months


## Question 2a) The output below is obtained after using the step() function using forward selection, ...
starting with a model with just the intercept term. What is the model selected based on forward selection?

**Answer 2a**

Share ~ discount + promo + price

## Question 2b) Your client asks you to explain ...
what each step in the output shown above means. Explain the forward selection procedure to your client, for this output.

**Answer 2b**

We start with a prediction based on about the average Share value, or what we call the intercept-only model. Essentially, we start without using price, nielsen, discount, promo, or time to help predict Share - so the average Share is the best we could do in that case.

Then, we examine the predictive power of using only one of the prediction variables. Since we are using the statistical code R to decide our model using a forward selection process, we are calculating whether adding an additional predictor variable to our prediction model decreases the AIC, which is a measure of the model's ability to decrease unexplained error. The AIC value takes into account that adding additional predictors to the model the model can actually get worse at the prediction of new data because the model becomes to rigid based on the data we used to train it with. We want to find a balance that provides good performance. Using AIC aids us in that selection. Again, we try the model with only one predictor variable, and we try all the variables, and select the first predictor variable that produces the lowest AIC value. We also verify that the addition of the new predictor does not increase AIC from the previous model we used. After we select a model with the "best" of the single predictor variables, we examine all the models with that variable, and one of the other predictors. Again we choose the second predictor to add to the model that produces the lowest AIC, and also confirm it doesn't increase AIC compared to the previous model. We continue to try adding predictor variables to the model with the lowest AIC, or until we run out of predictors, or find that adding a new predictor causes the AIC to increase.

If you are interested the formula for AIC is: (n * ln(SSE / n)) + 2p, where n is the number of observations in the mode, SSE is the sum squared residual error of the model, and p is the number of parameters the model includes. As predictor variables are added we expect SSE to decrease, but p increases. Our model selection method attempts the find the model that balances those two effects.

## Question 2c) Your client asks if he should go ahead and use the models selected in part 2a.
What advice do you have for your client?

**Answer 2c**

I advise that we also investigate which model is identified with backwards selection, and with stepwise selection which are other methods to identify candidate models. After we have identified those models, I recommend investigating the PRESS statistic for each model, and talking with subject matter experts about the ability to collect and maintain the predictor variables in any of the identified models. Again, this is a balancing act to identify the "best" model that will also be maintainable and makes sense to you (the client).

## Question 3) (No R required) Your client asks you to compare and contrast between R2 and the adjusted R2, ...
specifically: name one advantage of R2 over the adjusted R2, and name one advantage of the adjusted R2 over R2.

**Answer 3**

Benefit of **R2**: Looking at a plot of R2p vs. number of parameters an analyst can use judgment to determine the number of regressors for the final model by examining where the curve of the plot becomes apparent.



Benefit of **R2-Adjusted**: R2Adjusted takes into consideration the effect of adding additional parameters to the model and the loss of degrees of freedom (n - p). R2Adjusted can be used to compare R2Adjusted values of models with different numbers of parameters and if the model with an additional parameter's R2Adjusted value exceeds the R2Adjusted value of the models with fewer predictors, then we know that the additional parameter is significant.


## Question 4) Include the function your group wrote to compute the PRESS statistic 
(Question 2 in Guided Question Set).

```{r q4}
calculatePRESS <- function(theModel) {
  
  sumPRESS = 0
  
  for (i in 1:length(hatDiagonals)){
    sumPRESS <- sumPRESS + ((theModel$residuals[i]) / (1 - hatDiagonals[i]))^2
  }
  
  return(sumPRESS)
}
```

## Question 5)
Please remember to complete the Module 7 Guided Question Set Participation Self-and Peer-Evaluation Questions via Test & Quizzes on Collab.

**Answer Question 5**: Will do.


